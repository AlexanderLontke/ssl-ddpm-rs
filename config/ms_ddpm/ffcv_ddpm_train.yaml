name: &NAME rs-ddpm-ms
seed: 42

sentinel_2_pipeline: &S2_PIPELINE
  - module: remote_sensing_core.transforms.ffcv.clipping.Clipping
    kwargs:
      clip_values: [0, 10000]
  - module: remote_sensing_core.transforms.ffcv.min_max_scaler.MinMaxScaler
    kwargs:
      minimum_value: 0
      maximum_value: 10000
  - module: remote_sensing_core.transforms.ffcv.padding.Padding
    kwargs:
      padding: 4
      padding_value: 0
  - module: remote_sensing_core.transforms.ffcv.convert.Convert
    kwargs:
      target_dtype: "float32"
  - module: ffcv.transforms.ToTensor

# DATA SET CONFIG
train_torch_data_loader:
  module: ffcv.loader.Loader
  kwargs:
    fname: /netscratch2/alontke/master_thesis/data/ffcv/ben-ge-train20_s2_rgb_infrared.beton
    batch_size: 24
    num_workers: 8
    order:
      module: ffcv.loader.OrderOption
      args: [ 3 ]
    pipelines:
      sentinel_2: *S2_PIPELINE

validation_torch_data_loader:
  module: ffcv.loader.Loader
  kwargs:
    fname: /netscratch2/alontke/master_thesis/data/ffcv/ben-ge-test20_s2_rgb_infrared.beton
    batch_size: 24
    num_workers: 8
    order:
      module: ffcv.loader.OrderOption
      args: [ 1 ]
    pipelines:
      sentinel_2: *S2_PIPELINE
        


# MODEL INSTANTIATION
pl_module:
  module: "lit_diffusion.ddpm.lit_ddpm.LitDDPM"
  kwargs:
    diffusion_target: eps
    schedule_type: linear
    beta_schedule_steps: 1000
    beta_schedule_linear_start: 0.0001
    beta_schedule_linear_end: 0.02
    learning_rate: 0.00001
    data_key: 0 # "sentinel_2"
    learning_rate_scheduler_config:
      module: torch.optim.lr_scheduler.LinearLR
      delay: 1
    p_theta_model:
      module: remote_sensing_ddpm.p_theta_models.ddpm_cd_model.sr3_modules.unet.UNet
      kwargs:
        in_channel: 4
        out_channel: 4
        norm_groups: 32
        inner_channel: 128
        channel_mults: [ 1, 2, 4, 8, 8 ]
        attn_res: [ 16 ]
        res_blocks: 2
        dropout: 0.2
        image_size: 128

# MODEL TRAINING
pl_trainer:
  accelerator: gpu
  max_epochs: 10
  log_every_n_steps: 1
  precision: "16-mixed"
  # gradient_clip_algorithm: "norm"
  enable_checkpointing: True
  # UNCOMMENT FOR DEBUGGING
  # fast_dev_run: True

pl_wandb_logger:
  project: *NAME

pl_checkpoint_callback:
  monitor: "val/mse_loss"
  save_top_k: 3
  every_n_epochs: 5

sampling:
  shape: [4, 128, 128]
  strict_ckpt_loading: False
  device: cuda
  batch_size: 16
  safe_intermediaries_every_n_steps: 100
  clip_denoised: False
